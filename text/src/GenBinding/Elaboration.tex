\chapter{Elaboration}\label{ch:elaboration}

For the meta-theoretical formalization of programming language we need
properties of the semantical definitions. For instance, for type-theory proofs
via progress and preservation we generally need substitution properties of the
typing relation, and all the other boilerplate that is necessary to prove it.

There are multiple ways to the boilerplate lemmas for use in mechanizations. We
can develop a \emph{code generator} that produces code for a proof-assistant.
Alternatively, we can develop a \emph{datatype-generic} library inside a
proof-assistant. Both approaches have different trade-offs.


\paragraph{Generic Library}

Alternatively, we can with (well-formed) \Knot specifications as the codes of a
generic universe. The main benefit of a library is, that its code, including all
proofs, can be checked separately independently of a concrete specification.
Hence, instantiating the library is guaranteed to yield valid theorems for all
specifications.

Disadvantages of a generic library:
\begin{itemize}
\item Hiding of the internals.
\item Induction over the generic generic representation is usually not the
  desired ont. Do not use datatypes of the extension directly, but instead
  write isomorphism to user defined types. This also applies to
  well-scopedness predicates and relations.
\item Generically handling relations with arbitrary arities is challenging.
\item Generic implementation shines through. For example, during
  simplification, the generic implementation might be exposed.
\item The statement of a generic lemma may not unify with all goals it applies
  to, before it has been properly specialized to a given specification. This
  impacts automatic proof search.
\item Proof discovery.
\end{itemize}


\paragraph{Code Generators}
A code generator can parse textual \Knot specifications and produces code for
use in a proof-assistant. In terms of usability, there are clear advantages.

The code generator can produce definition of datatypes and functions that are
close to what a human prover might write manually. Hence, the user can inspect
the code to understand the provided functionality in detail. Moreover, since the
code generator can specialize the statements of lemmas to the given
specification, it is much easier for the user to look at the provided proofs
and for proof automation to apply the provided proofs.

The main downside of a code generator is that the output still needs to be
checked. This raises the question if correct code is generated in all cases.
Proofs can also be implemented differently, depending on the available methods
in the proof assistant. For instance, Coq has a powerful scripting language to
automate writing proofs. However, very generic proof scripts tend to be brittle
and can possibly take a long time to execute. Furthermore, reasoning about the
correctness of the code generator not only involves the language of the proof
assistant, but also that of the scripting system.




\begin{itemize}
\item We defined the semantics of \Knot specification generically and also
  implemented boilerplate functions generically.

\item In an actual implementation, for instance a code generator, these generic
  definitions needs to be expanded into specialized code for a particular
  specification, or put differently, we need to turn the generic implementation
  into an elaboration into the target language.

\item Elaborating the functional definitions is comparably easy. Much more
  challenging is to elaborate a specification into lemmas and proofs.

\item Programming language mechanizations typically rely on many boilerplate
  properties of the boilerplate operations that we introduced in the previous
  chapter.

\item The elaborations of specification into these boilerplate lemmas and their
  proofs will be the focus of this chapter.

\item There are too many lemmas to give an exhaustive account of all the
  necessary elaborations. Instead we concentrate on representative and key
  lemmas.

\item The boilerplate lemmas themselves are not novel. The novelties lie in our
  elaboration of them. Hence we specifically turn our attention to the
  elaboration methodology.
\end{itemize}

\paragraph{Methodology}
There are two connected problems that we solve:
\begin{itemize}
\item Generic proofs of the boilerplate lemmas.

\item Once a proof has been generically established in a meta-language, the
  proof structure is not directly accessible, e.g. to implement an elaboration
  for these proofs.

  One can aim to implement an elaboration that follows the same structure as the
  generic proof, but the faithfulness and therefore correctness of the
  elaboration is called into question.

\item
  We solve this problem by factoring the generic proofs through domain-specific
  witness languages. This splits the generic proof into multiple distinct parts:
  \begin{enumerate}
  \item A (syntax-directed) elaboration into a witness language that we designed
    for the given class of lemmas.
  \item A semantics of the witness langauge.
  \item The correctness of the elaboration, i.e. the produced witness indeed
    encodes a proof of the desired lemma w.r.t. the chosen semantics.
  \item A soundness proof of the semantics of the witness language, e.g. the
    statement that a witness proves w.r.t. to the chosen semantics is valid (in
    our proof meta-language).
  \end{enumerate}

\item The benefit of this approach is that we can give a formal definition of
  elaborations and analyze the elaborations formally, i.e. proof their
  correctness. At the same time, we minimize the part of the generic proof that
  is not formally accessible to the soundness of the witness language.
\end{itemize}


\paragraph{Overview}

The sections in this chapter show how the witness language methodology is
applied to several classes of boilerplate lemmas. Section
\ref{ssec:elab:interaction:overview} discusses common interaction lemmas between
syntactic operations. Section \ref{sec:elab:wellscopedness} deals with the
well-scopedness lemmas that we discussed in Section
\ref{sec:gen:overview:formalization:semantics} and
\ref{sec:gen:formalization:metatheory}, i.e. lemmas that prove that indices of
relations are always well-scoped. Section \ref{sec:elab:shifting} covers
shifting and substitution lemmas for relations. Section
\ref{sec:elab:impl:generic} discusses a generic implementation of \Knot in \Coq
and generic proofs of lemmas that follow the methodology of this chapter.
Finally, Section \ref{sec:elab:impl:codegen} covers the implementation of our
code generator \Needle.


%% \stevennote{MOVE}{To further reduce the hand-written boilerplate, we have set up
%%   the \Knot specification language in such a way that it provides all the
%%   necessary information to generically state and prove a wide range of these
%%   properties.}

%% \footnote{In fact, we provide more such lemmas than any other framework based on
%%   first-order representations -- see Section~\ref{sec:related}.}

%% \stevennote{MOVE}{Below we discuss different kinds of ubiquitous lemmas that
%%   \Needle covers; Appendix~\ref{app:lemmas} provides more detail.}

%% \stevennote{MOVE}{It is quite challenging to tackle these boilerplate lemmas
%%   generically because their exact statements, and in particular which premises
%%   are needed, depend highly on the dependencies between sorts and of the
%%   associated data in environments.}

\input{src/GenBinding/Elaboration/Interaction} \clearpage
\input{src/GenBinding/Elaboration/WellScopedness}
\input{src/GenBinding/Elaboration/RelShifting}
\input{src/GenBinding/Elaboration/RelSubstitution}
\input{src/GenBinding/Elaboration/Implementation}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:
